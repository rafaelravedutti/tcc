fn grid_config(img : image_struct) -> (i32, i32, i32) {
  ( img.width + (128 - img.width % 128),
    img.height + (4 - img.height % 4),
    1 )
}

fn block_config(img : image_struct) -> (i32, i32, i32) {
  (128, 4, 1)
}

fn read(buf: Buffer, i: i32) -> f32 {
  bitcast[&[1][f32]](buf.data)(i)
}

fn write(buf: Buffer, i: i32, v: f32) -> () {
  bitcast[&mut[1][f32]](buf.data)(i) = v
}

fn get_image_offset(img : image_struct) -> i32 {
  img.width * 2 + 5
}

/* Allocate image on device */
fn alloc_gpu_image(img : image_struct) -> Buffer {
  let acc = cuda_accelerator(0);

  acc.alloc((img.width + 4) * (img.height + 4) * sizeof[f32]())
}

/* Upload image */
fn upload_image(img : image_struct) -> () {
  copy(img.data, img.gpu_data, (img.width + 4) * (img.height + 4) * sizeof[f32]());
}

/* Get offsets */
fn get_offsets() -> Buffer {
  let acc = cuda_accelerator(0);
  let offsets = [ 1.0f, 1.0f, -1.0f, 1.0f, 0.0f, 1.0f, 0.0f,
                  1.0f, 1.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f    ];
 
  let offsets_cpu = alloc_cpu(14 * sizeof[f32]());
  let offsets_gpu = acc.alloc(14 * sizeof[f32]());

  for i in range(0, 13) {
    write(offsets_cpu, i, offsets(i));
  }

  copy(offsets_cpu, offsets_gpu, 14 * sizeof[f32]());
  release(offsets_cpu);
  offsets_gpu
}

/* Iterates over an image on GPU architectures */
fn fake_iterate(img : image_struct, body: fn(int,int) -> ()) -> () {
  let acc = cuda_accelerator(0);
  let grid = grid_config(img);
  let block = block_config(img);

  with acc.exec(grid, block) @{
    let x = acc.bidx() * acc.bdimx() + acc.tidx();
    let y = acc.bidy() * acc.bdimy() + acc.tidy();

    body(x, y);
  }
}

/* Serial iterate for use in case of data dependency issues */
fn serial_iterate(img : image_struct, body: fn(int, int) -> ()) -> () {
  let block_size = 7; /* Pixels per block */
  let offset = get_image_offset(img);

  for i in step_range(0, img.height - (block_size + 1), block_size) {
    for j in step_range(0, img.width - (block_size + 1), block_size) {
      for k in range(0, block_size - 1) {
        for l in range(0, block_size - 1) {
          let x = j + l + offset;
          let y = i + k;

          body(x, y);
        }
      }
    }
  }

  for i in range(img.width - block_size, img.width - 1) {
    for j in range(0, img.height - 1) {
      body(i + offset, j);
    }
  }

  for i in range(img.height - block_size, img.height - 1) {
    for j in range(0, img.width - (block_size + 1)) {
      body(j + offset, i);
    }
  }
}

/* Iterate for stencils */
fn stencil_iterate(
  img : image_struct,
  filter : filter_struct,
  buffer_to_data : bool,
  body: fn(int, int, Buffer, Buffer, Buffer) -> ()) -> () {
  let acc = cuda_accelerator(0);
  let grid = grid_config(img);
  let block = block_config(img);
  let offset = get_image_offset(img);

  let mut arr_in : Buffer;
  let mut arr_out : Buffer;
  let mask = acc.alloc(filter.size * sizeof[f32]());

  if buffer_to_data {
    arr_in = img.gpu_buffer;
    arr_out = img.gpu_data;
  } else {
    arr_in = img.gpu_data;
    arr_out = img.gpu_buffer;
  }

  copy(filter.data, mask, filter.size * sizeof[f32]());

  with acc.exec(grid, block) @{
    let x = acc.bidx() * acc.bdimx() + acc.tidx();
    let y = acc.bidy() * acc.bdimy() + acc.tidy();

    if x > 1 && x < img.width - 1 && y > 1 && y < img.height - 1 @{
      body(x + offset, y, arr_in, arr_out, mask);
    }
  }

  release(mask);
}

fn gradient_iterate(
  img : image_struct,
  buffer_to_data : bool,
  copy_magnitudes : bool,
  load_image : bool,
  body: fn(int, int, int, Buffer, Buffer, Buffer, Buffer) -> ()) -> () {
  let acc = cuda_accelerator(0);
  let grid = grid_config(img);
  let block = block_config(img);
  let offset = get_image_offset(img);

  let mut arr_in : Buffer;
  let mut arr_out : Buffer;

  if buffer_to_data {
    arr_in = img.gpu_buffer;
    arr_out = img.gpu_data;
  } else {
    arr_in = img.gpu_data;
    arr_out = img.gpu_buffer;
  }


  with acc.exec(grid, block) @{
    let x = acc.bidx() * acc.bdimx() + acc.tidx();
    let y = acc.bidy() * acc.bdimy() + acc.tidy();

    if x >= 0 && x < img.width && y >= 0 && y < img.height @{
      body(x + offset, y, x, arr_in, arr_out, img.gpu_dx, img.gpu_dy);
    }
  }

  if load_image {
    copy(arr_out, img.data, (img.width + 4) * (img.height + 4) * sizeof[f32]());
  }
}

fn release_image_from_device(img : image_struct) -> () {
  release(img.gpu_data);
  release(img.gpu_buffer);
  release(img.gpu_dx);
  release(img.gpu_dy);
  release(img.offsets);
}

fn exp(a : f32) -> f32 {
  cuda_intrinsics.expf(a)
}
